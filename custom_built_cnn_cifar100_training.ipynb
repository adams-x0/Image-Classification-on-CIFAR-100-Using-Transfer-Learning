{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZYH6miArl6s"
      },
      "outputs": [],
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DvKKkdwuEOf"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install tensorflow"
      ],
      "metadata": {
        "id": "m0wN-jFwpYIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWq-3asQskH2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_Y9CgJyTuNyo",
        "outputId": "21aad8d1-d23c-4ebb-8eed-582ad91c01c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFQj_SreuUGj"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlAX4MDJuYru"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv7HZABNuZoz",
        "outputId": "66ceba43-cabb-4012-846d-db25f8369a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RandomFlip name=random_flip_4, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "HORIZONTAL = \"horizontal\"\n",
        "VERTICAL = \"vertical\"\n",
        "HORIZONTAL_AND_VERTICAL = \"horizontal_and_vertical\"\n",
        "tf.keras.layers.RandomFlip(\n",
        "    mode=HORIZONTAL_AND_VERTICAL, seed=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM6Cu_cLuiAI",
        "outputId": "ed4dca0a-9f65-40ef-d56e-02f9c4ccecfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RandomZoom name=random_zoom_4, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "height_factor=(0.2, 0.3)\n",
        "tf.keras.layers.RandomZoom(\n",
        "    height_factor,\n",
        "    width_factor=None,\n",
        "    fill_mode='reflect',\n",
        "    interpolation='bilinear',\n",
        "    seed=None,\n",
        "    fill_value=0.0,\n",
        "    data_format=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTS-_0Svuls1",
        "outputId": "f8fe4980-dea6-45ee-e455-76af595a5d6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Rescaling name=rescaling_6, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "scale=1./255\n",
        "tf.keras.layers.Rescaling(\n",
        "    scale, offset=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxmD8vFTu-MJ"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 180\n",
        "HORIZONTAL = \"horizontal\"\n",
        "VERTICAL = \"vertical\"\n",
        "height_factor=(0.2, 0.3)\n",
        "\n",
        "train_datagen = tf.keras.Sequential(\n",
        "  [\n",
        "    # layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.RandomFlip(mode=HORIZONTAL_AND_VERTICAL, seed=None),\n",
        "    layers.RandomZoom(\n",
        "      height_factor,\n",
        "      width_factor=None,\n",
        "      fill_mode='reflect',\n",
        "      interpolation='bilinear',\n",
        "      seed=None,\n",
        "      fill_value=0.0,\n",
        "      data_format=None\n",
        "    )\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HizmhFu60Ry0"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGF3Ek4f0MD4"
      },
      "outputs": [],
      "source": [
        "test_datagen = tf.keras.Sequential([\n",
        "    # layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "    layers.Rescaling(1./255)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqAYdeCtCA86"
      },
      "source": [
        "### Upload in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXv0GQycCH01"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hUtV3eNCKTX"
      },
      "source": [
        "### Extract the contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9i5-e80CAZL"
      },
      "outputs": [],
      "source": [
        "# import tarfile\n",
        "\n",
        "# # Extract to current directory\n",
        "# with tarfile.open(\"cifar-100-python.tar.gz\", \"r:gz\") as tar:\n",
        "#     tar.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and preprocess CIFAR-100 data"
      ],
      "metadata": {
        "id": "8wpQfNBtxxI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict = unpickle('cifar-100-python/train')\n",
        "test_dict = unpickle('cifar-100-python/test')"
      ],
      "metadata": {
        "id": "XpJwbSbNxzyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "Reshape flat CIFAR-100 image data into (num_samples, channels, height, width)\n",
        "Each image has 3072 values: 1024 each for R, G, B channels\n",
        "Using -1 lets NumPy automatically infer the number of samples (should be 50000)\n",
        "Transpose to (num_samples, height, width, channels) to match TensorFlow's expected format\n",
        "Convert fine-grained class labels (0–99) from a Python list to a TensorFlow tensor\n",
        "This is needed for compatibility with tf.data and model training\n",
        "</pre>"
      ],
      "metadata": {
        "id": "qYkIAJmIx8gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshape and reorder axes"
      ],
      "metadata": {
        "id": "JVmS6JVIyGui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_dict[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1).astype('float32')\n",
        "y_test = tf.convert_to_tensor(test_dict[b'fine_labels'])"
      ],
      "metadata": {
        "id": "PxC3Zo6AyJ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_dict[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1).astype('float32')\n",
        "y_train = tf.convert_to_tensor(train_dict[b'fine_labels'])"
      ],
      "metadata": {
        "id": "5fARoAgjyc4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build tf.data.Dataset and apply train_datagen & test_datagen pipelines"
      ],
      "metadata": {
        "id": "RCqSW-FUyfvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "ogss8rSsy1DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tf.data.Dataset from training images and labels\n",
        "# Each element will be a (image, label) pair\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "# Shuffle the dataset to randomize the order of samples\n",
        "# A buffer size of 10000 provides good mixing\n",
        "train_ds = train_ds.shuffle(10000)\n",
        "# Group the dataset into batches of size BATCH_SIZE\n",
        "train_ds = train_ds.batch(BATCH_SIZE)\n",
        "# Apply the preprocessing and data augmentation defined in train_datagen\n",
        "# Resizing, rescaling, flipping, and zooming will be applied on-the-fly\n",
        "# train_ds = train_ds.map(lambda x, y: (train_datagen(x), y), num_parallel_calls=AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda x, y: (x, y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# Prefetch batches to improve training performance by overlapping data loading and model\n",
        "train_ds = train_ds.prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "5bHQCo6CzCfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_ds = test_ds.batch(BATCH_SIZE)\n",
        "# test_ds = test_ds.map(lambda x, y: (test_datagen(x), y), num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.map(lambda x, y: (x, y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "test_ds = test_ds.prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "2kT2SHW1zSo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2 - Building the CNN"
      ],
      "metadata": {
        "id": "qk2nzod5zVLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialising the CNN"
      ],
      "metadata": {
        "id": "1o1m9ehozZW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "fv-MJ644zsRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 - Convolution"
      ],
      "metadata": {
        "id": "TTgO1kz5zxV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(32, 32, 3), padding='same', strides=(2, 2)))\n",
        "cnn.add(tf.keras.layers.BatchNormalization())"
      ],
      "metadata": {
        "id": "qLvi2pPhz1Ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705e99d0-d944-49ce-860a-c9f392c5efd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 - Pooling"
      ],
      "metadata": {
        "id": "asfC1zkTz6PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.25)) # Dropout after pooling"
      ],
      "metadata": {
        "id": "2JQipQrY0BHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a second convolutional layer"
      ],
      "metadata": {
        "id": "Ve1MykkK0Dt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', strides=(2, 2)))\n",
        "cnn.add(tf.keras.layers.BatchNormalization())\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.25))"
      ],
      "metadata": {
        "id": "jW1RnOgr0GrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a third convolutional layer"
      ],
      "metadata": {
        "id": "dQV8PMzh1SVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
        "# cnn.add(tf.keras.layers.BatchNormalization())\n",
        "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "# cnn.add(tf.keras.layers.Dropout(0.25))"
      ],
      "metadata": {
        "id": "snhBttUN1YWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - Flattening"
      ],
      "metadata": {
        "id": "_AazUKYX0LGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "HWnXjIkO0Ouy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 - Full Connection"
      ],
      "metadata": {
        "id": "GqrYARY00Sbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.BatchNormalization())\n",
        "cnn.add(tf.keras.layers.Dropout(0.3)) # More aggressive dropout before final layer"
      ],
      "metadata": {
        "id": "mwoZBqDr0YIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 - Output Layer"
      ],
      "metadata": {
        "id": "3Ecv3wkJ0dEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=100, activation='softmax'))"
      ],
      "metadata": {
        "id": "rr1dS7W70nP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3 - Training the CNN"
      ],
      "metadata": {
        "id": "eI45jHP80ryc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the CNN"
      ],
      "metadata": {
        "id": "IMdgObkn0u9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "loss = 'sparse_categorical_crossentropy', # because labels are integer class\n",
        "cnn.compile(\n",
        "    optimizer = Adam(learning_rate=2.5000e-04),\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "L19qvIZX0zhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ],
      "metadata": {
        "id": "7sBcYWqG01yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "monitor='val_loss', # What metric to watch\n",
        "factor=0.5, # Reduce LR by half\n",
        "patience=2, # Wait 3 bad epochs before acting\n",
        "verbose=1 # Print when LR changes\n",
        ")\n",
        "cnn.fit(train_ds,\n",
        "validation_data = test_ds,\n",
        "verbose=1,\n",
        "callbacks=[lr_scheduler],\n",
        "epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yb7cU6z07sw",
        "outputId": "e27eca33-7af7-4679-ab28-1c0ee56af43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.0299 - loss: 4.8041 - val_accuracy: 0.1219 - val_loss: 3.8929 - learning_rate: 2.5000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.0844 - loss: 4.0586 - val_accuracy: 0.1678 - val_loss: 3.5981 - learning_rate: 2.5000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.1216 - loss: 3.7856 - val_accuracy: 0.1991 - val_loss: 3.4471 - learning_rate: 2.5000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.1480 - loss: 3.6079 - val_accuracy: 0.2157 - val_loss: 3.3109 - learning_rate: 2.5000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.1738 - loss: 3.4721 - val_accuracy: 0.2249 - val_loss: 3.2578 - learning_rate: 2.5000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.1892 - loss: 3.3654 - val_accuracy: 0.2488 - val_loss: 3.1358 - learning_rate: 2.5000e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.2110 - loss: 3.2805 - val_accuracy: 0.2671 - val_loss: 3.0165 - learning_rate: 2.5000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.2211 - loss: 3.2042 - val_accuracy: 0.2751 - val_loss: 2.9743 - learning_rate: 2.5000e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.2306 - loss: 3.1487 - val_accuracy: 0.2867 - val_loss: 2.9170 - learning_rate: 2.5000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.2402 - loss: 3.1041 - val_accuracy: 0.2911 - val_loss: 2.8777 - learning_rate: 2.5000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.2484 - loss: 3.0524 - val_accuracy: 0.3087 - val_loss: 2.8012 - learning_rate: 2.5000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.2519 - loss: 3.0244 - val_accuracy: 0.3063 - val_loss: 2.7921 - learning_rate: 2.5000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.2571 - loss: 2.9996 - val_accuracy: 0.3184 - val_loss: 2.7431 - learning_rate: 2.5000e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.2661 - loss: 2.9590 - val_accuracy: 0.3012 - val_loss: 2.8106 - learning_rate: 2.5000e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.2659 - loss: 2.9407 - val_accuracy: 0.3252 - val_loss: 2.6995 - learning_rate: 2.5000e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.2739 - loss: 2.9232 - val_accuracy: 0.3294 - val_loss: 2.6701 - learning_rate: 2.5000e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.2828 - loss: 2.8916 - val_accuracy: 0.3343 - val_loss: 2.6455 - learning_rate: 2.5000e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.2770 - loss: 2.8935 - val_accuracy: 0.3247 - val_loss: 2.7005 - learning_rate: 2.5000e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.2840 - loss: 2.8571 - val_accuracy: 0.3365 - val_loss: 2.6383 - learning_rate: 2.5000e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.2853 - loss: 2.8506 - val_accuracy: 0.3505 - val_loss: 2.5861 - learning_rate: 2.5000e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.2879 - loss: 2.8332 - val_accuracy: 0.3513 - val_loss: 2.5657 - learning_rate: 2.5000e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.2917 - loss: 2.8217 - val_accuracy: 0.3440 - val_loss: 2.5790 - learning_rate: 2.5000e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2934 - loss: 2.8145\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.2934 - loss: 2.8145 - val_accuracy: 0.3464 - val_loss: 2.5734 - learning_rate: 2.5000e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.2974 - loss: 2.7830 - val_accuracy: 0.3534 - val_loss: 2.5431 - learning_rate: 1.2500e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.3032 - loss: 2.7694 - val_accuracy: 0.3611 - val_loss: 2.5255 - learning_rate: 1.2500e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78a0c4ce0150>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finally, evaluate its performance"
      ],
      "metadata": {
        "id": "L5JVG--t1FDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the trained model on the test dataset\n",
        "test_loss, test_accuracy = cnn.evaluate(test_ds)\n",
        "# Print the results\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "WF9hhGBj1ItX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b21ece-7fea-4c73-ec33-158c1479ba2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3623 - loss: 2.5172\n",
            "Test Loss: 2.5255\n",
            "Test Accuracy: 0.3611\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}